{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"contributing/","title":"Contributing","text":"<p>Work in progress.... Check the CONTRIBUTING.md</p>"},{"location":"conventions/","title":"Conventions","text":"<ul> <li>The project folder must be a Git repository, with a least one commit</li> <li><code>Dockerfile</code> should be present in the root of the project directory   (this can be overridden with flags).   The <code>Dockerfile</code> will be used to build the project into a runnable docker image.</li> <li>Kubernetes descriptor files must be located in the <code>k8s</code> folder (only needed for <code>deploy</code> and <code>promote</code>)</li> <li>The <code>k8s</code> folder can also contain custom scripts that should be run during deployment</li> <li>The name of the directory will be used as the name of the application<ul> <li>If running in CI, <code>ENV</code> variables will be used to determine the name of the project being built</li> <li>The name can also be overridden using the <code>IMAGE_NAME</code> environment variable</li> </ul> </li> <li>The current commit id will be used as docker tag</li> <li>The current branch will be used as docker tag. If you're on the <code>master</code> or <code>main</code>   branch the docker image will also be tagged <code>latest</code>. The <code>latest</code> tag will also be pushed in that case.</li> <li>Targets (deployment targets) are configured in <code>.buildtools.yaml</code> file(s)</li> <li><code>.buildtools.yaml</code> file(s) will be merged together hierarchically and can be used for multiple   projects</li> <li>Use Target names to use specific <code>k8s</code> files for different deployment targets</li> </ul>"},{"location":"faq/","title":"Frequently Asked Questions","text":"<p>Or stuff just good-to-know...</p>"},{"location":"faq/#what-happened-to-x-action","title":"What happened to X-action?","text":"<p>We deprecated the build, push, deploy Github actions in favour of the new setup-buildtools-action</p>"},{"location":"faq/#dealing-with-different-docker-versions","title":"Dealing with different docker versions","text":"<p>buildtools defaults to using the latest version of the docker client (the actual version is determined by the docker client library that is used). This might cause issues if your docker server is running an older version.</p> <p>Errors like: <pre><code>Error response from daemon: client version 1.41 is too new. Maximum supported API version is 1.40\n</code></pre></p> <p>The docker client version can be specified with the <code>env</code> variable <code>DOCKER_API_VERSION</code> Depending on your setup you might be able to use <code>export</code> somewhere \"globally\" <pre><code>export DOCKER_API_VERSION=1.40\n</code></pre> Or just use it when running the actual command <pre><code>DOCKER_API_VERSION=1.40 build\n</code></pre></p>"},{"location":"installation/","title":"Installation","text":"<p>You can install the pre-compiled binary (in several different ways), use Docker or compile from source.</p>"},{"location":"installation/#installation-pre-built-binaries","title":"Installation pre-built binaries","text":"<p>Homebrew tap</p> <pre><code>$ brew install buildtool/taps/build-tools\n</code></pre> <p>Shell script <pre><code>$ curl -sfL https://raw.githubusercontent.com/buildtool/build-tools/main/install.sh | sh\n</code></pre> Manually</p> <p>Download the pre-compiled binaries from the releases page and copy to the desired location.</p>"},{"location":"installation/#running-with-docker","title":"Running with Docker","text":"<p>You can also use it within a Docker container. To do that, you\u2019ll need to execute something more-or-less like the following: <pre><code>$ docker run --rm --privileged \\\n  -v $PWD:/repo \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  -w /repo \\\n  -e DOCKER_USERNAME \\\n  -e DOCKER_PASSWORD \\\n  buildtool/build-tools build\n</code></pre></p>"},{"location":"installation/#compiling-from-source","title":"Compiling from source","text":"<p>Here you have two options:</p> <p>If you want to contribute to the project, please follow the steps on our contributing guide.</p> <p>If you just want to build from source for whatever reason, follow these steps:</p> <p>Clone:</p> <pre><code>git clone https://github.com/buildtool/build-tools\ncd build-tools\n</code></pre> <p>Get the dependencies:</p> <pre><code>go get ./...\n</code></pre> <p>Build:</p> <pre><code>go build  ./cmd/build/build.go\n</code></pre> <p>Verify it works:</p> <pre><code>./build --version\n</code></pre>"},{"location":"introduction/","title":"Introduction","text":"<p>build-tools is a set of highly opinionated tools for creating and building components/services into docker images and deploying them to Kubernetes clusters.</p> <p>By following the conventions set by the tools, building and deploying applications is made simpler. It streamlines the process of building and deploying using the same commands on your local development machine and in a CI/CD pipeline.</p> <p>The basic usage is <code>build</code>, <code>push</code> and <code>deploy</code> (or <code>promote</code> if you are using GitOps). This will build a docker image of your code using your provided Dockerfile making it possible to customize the actual build process. The built image is then pushed to a Docker Registry of your choosing. This is of course optional, but a necessary step to be able to deploy the built image on a (non-local) Kubernetes cluster. Finally, the code is deployed to the Kubernetes cluster using the provided descriptor files.</p>"},{"location":"quickstart/","title":"Quickstart","text":""},{"location":"quickstart/#pre-requisites","title":"Pre requisites:","text":"<p>In order to work with these tools you need:</p> <ul> <li>Buildtools installed (of course)</li> <li>Docker - read more about options here</li> <li>Kubernetes - if you're using for example Docker for Mac Kubernetes can easily be enabled.</li> </ul> <p>In this example we will build, push and deploy a sample Go project.</p> <p>Create a Git repository and add a single main package with a http server:</p> <pre><code>mkdir quickstart\ncd quickstart\ngit init\n</code></pre> <pre><code>// main.go\npackage main\n\nimport (\n    \"fmt\"\n    \"net/http\"\n)\n\nfunc main() {\n    http.HandleFunc(\"/\", HelloServer)\n    http.ListenAndServe(\":8080\", nil)\n}\n\nfunc HelloServer(w http.ResponseWriter, r *http.Request) {\n    fmt.Fprintf(w, \"Hello, %s!\", r.URL.Path[1:])\n}\n</code></pre> <p>Add a Dockerfile describing how to build your code:</p> <pre><code># Dockerfile\nFROM golang:1.15 as build\nWORKDIR /build\nADD . /build\n\nRUN GOOS=linux GOARCH=amd64 go build main.go\n\nFROM debian:buster-slim\nCOPY --from=build /build/main /\nCMD [\"/main\"]\n</code></pre> <p>Add the files to source control and commit: <pre><code>git add .\ngit commit -m \"Init\"\n</code></pre> Build the docker image:</p> <pre><code>build\n</code></pre> <p>After the build completes you should see output like</p> <pre><code>...\nSuccessfully tagged noregistry/quickstart:latest\n</code></pre> <p>Try to run your newly built docker image: <pre><code>docker run --rm -p 8080:8080 noregistry/quickstart:latest\n</code></pre> and try to access it: <pre><code>curl localhost:8080/buildtools\n</code></pre> You should see a response like: <pre><code>Hello, buildtools!\n</code></pre></p> <p>Let's try to deploy it to our local Kubernetes cluster, in order for this to work we need a Kubernetes descriptor file. Create a <code>k8s</code> folder and a file <code>deploy.yaml</code>:</p> <pre><code># k8s/deploy.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: quickstart\n  annotations:\n    kubernetes.io/change-cause: \"${TIMESTAMP} Deployed commit id: ${COMMIT}\"\n  labels:\n    app: quickstart\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: quickstart\n  template:\n    metadata:\n      labels:\n        app: quickstart\n    spec:\n      containers:\n      - name: quickstart\n        imagePullPolicy: IfNotPresent\n        image: ${IMAGE}\n</code></pre> <p>This will create Kubernetes deployment, basically starting your application inside the Kubernetes cluster.</p> <pre><code>deploy --context docker-desktop\n</code></pre> <pre><code>kubectl --context docker-desktop get pods\n\nquickstart-b4c5bc467-lqk6r      1/1     Running        0          3s\n</code></pre>"},{"location":"ci/azure/","title":"Azure Devops","text":"<p>Azure Devops is configured with a <code>azure-pipelines.yml</code> file in your project.</p> <pre><code>resources:\n  containers:\n  - container: build-tools\n    image: buildtool/build-tools:latest\n\njobs:\n- job: build_and_deploy\n  pool:\n    vmImage: 'Ubuntu 16.04'\n  container: build-tools\n  steps:\n  - script: |\n      build\n      push\n    name: build\n    env:\n      QUAY_PASSWORD: $(QUAY_PASSWORD)\n  - script: deploy staging\n    name: deploy_staging\n    condition: succeeded()\n</code></pre>"},{"location":"ci/buildkite/","title":"Buildkite","text":"<p>Buildkite is configured with <code>.buildkite/pipeline.yml</code> file in your project.</p>"},{"location":"ci/buildkite/#buildkite-plugin","title":"Buildkite plugin","text":"<p>Using the Buildkite plugin for buildtools is probably the simplest way</p> <pre><code>steps:\n  - command: build\n    label: build\n    plugins:\n      - buildtool/buildtools:\n  - wait\n\n  - command: push\n    label: push\n    plugins:\n      - buildtool/buildtools:\n\n  - block: \":rocket: Release PROD\"\n    branches: \"main\"\n\n  - command: deploy prod\n    label: Deploy PROD\n    branches: \"main\"\n    plugins:\n      - buildtool/buildtools:\n          config: s3://my-buildkite-secrets/configs/myapp/env\n</code></pre>"},{"location":"ci/buildkite/#docker-plugin","title":"Docker plugin","text":"<p>build-tools can also be used with the Buildkite docker-plugin</p> <pre><code>steps:\n  - command: |-\n      build\n      push\n    label: build\n    plugins:\n      - docker#v3.3.0:\n          image: buildtool/build-tools\n          volumes:\n            - \"/var/run/docker.sock:/var/run/docker.sock\"\n          propagate-environment: true\n  - wait\n\n  - block: \":rocket: Release PROD\"\n    branches: \"main\"\n\n  - command: |-\n      deploy prod\n    label: Deploy PROD\n    branches: \"main\"\n    plugins:\n      - docker#v3.3.0:\n          image: buildtool/build-tools\n          volumes:\n            - \"/var/run/docker.sock:/var/run/docker.sock\"\n          propagate-environment: true\n</code></pre>"},{"location":"ci/ci/","title":"Continuous Integration","text":"<p>Commands recognize which CI/CD environment they are executed in based on which environment variables are present. The following variables are checked to determine which CI/CD tool that we run under.</p> Environment variable CI/CD <code>BUILDKITE_PIPELINE_SLUG</code> Buildkite <code>CI_PROJECT_NAME</code> Gitlab CI <code>RUNNER_WORKSPACE</code> Github Actions <code>TEAMCITY_PROJECT_NAME</code> TeamCity <code>BUILD_REPOSITORY_NAME</code> Azure Devops"},{"location":"ci/github/","title":"Github Actions","text":"<p>Build-tools can also be used within our official build-tools actions through GitHub Actions</p> <p>You can create a workflow by putting YAML configuration to <code>.github/workflows/build.yml</code>.</p> <p>Below is a simple snippet to use the setup-buildtools-action in your workflow:</p> <pre><code>name: Buildtool\non: [push]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v1\n      - uses: buildtool/setup-buildtools-action@v1\n      - run: build\n</code></pre> <p>Read more about available commands:</p> <p>For detailed intructions please follow GitHub Actions syntax.</p>"},{"location":"ci/gitlab/","title":"Gitlab CI","text":"<p>Gitlab CI is configured with a <code>.gitlab-ci.yaml</code> file in your project.</p> <pre><code>stages:\n  - build\n  - deploy-staging\n  - deploy-prod\n\nvariables:\n  DOCKER_HOST: tcp://docker:2375/\n\nimage: buildtool/build-tools:latest\n\nbuild:\n  stage: build\n  services:\n    - docker:dind\n  script:\n  - build\n  - push\n\ndeploy-to-staging:\n  stage: deploy-staging\n  when: on_success\n  script:\n    - echo Deploy to staging.\n    - deploy staging\n  environment:\n    name: staging\n\ndeploy-to-prod:\n  stage: deploy-prod\n  when: on_success\n  script:\n    - echo Deploy to PROD.\n    - deploy prod\n  environment:\n    name: prod\n  only:\n    - main\n</code></pre>"},{"location":"ci/teamcity/","title":"TeamCity","text":"<p>TeamCity can be configured with a <code>.teamcity/settings.kts</code> file in your project.</p> <pre><code>import jetbrains.buildServer.configs.kotlin.v2018_2.*\nimport jetbrains.buildServer.configs.kotlin.v2018_2.buildSteps.ScriptBuildStep\nimport jetbrains.buildServer.configs.kotlin.v2018_2.buildSteps.script\nimport jetbrains.buildServer.configs.kotlin.v2018_2.triggers.finishBuildTrigger\nimport jetbrains.buildServer.configs.kotlin.v2018_2.triggers.vcs\n\nversion = \"2019.1\"\n\nproject {\n    buildType(BuildAndPush)\n}\n\nobject BuildAndPush : BuildType({\n    name = \"BuildAndPush\"\n\n    steps {\n        script {\n            name = \"build and push\"\n            scriptContent = \"\"\"\n                build &amp;&amp; push\n            \"\"\".trimIndent()\n            dockerImage = \"buildtool/buildtools\"\n            dockerImagePlatform = ScriptBuildStep.ImagePlatform.Linux\n            dockerPull = true\n            dockerRunParameters = \"\"\"\n                -v /var/run/docker.sock:/var/run/docker.sock\n                --rm\n            \"\"\".trimIndent()\n        }\n    }\n\n    triggers {\n        vcs {}\n    }\n})\n</code></pre>"},{"location":"commands/build/","title":"build","text":"<p>Performs a <code>docker build</code>, using a <code>Dockerfile</code> to build the application and tags the resulting image. By following the conventions no additional flags are needed, but the following flags are available:</p> Flag Description <code>--file</code>,<code>-f</code> <code>&lt;path to Dockerfile&gt;</code> Used to override the default <code>Dockerfile</code> location (which is <code>$PWD</code>), or <code>-</code> to read from `stdin <code>--no-login</code> Disables login to docker registry (good for local testing) <code>--no-pull</code> Disables pulling of remote images if they already exist (good for local testing) <code>--build-arg key=value</code> Additional Docker build-arg <code>--platform value</code> Specify target platform(s) for multi-arch builds. Single platform: <code>--platform linux/amd64</code> or multiple platforms: <code>--platform linux/amd64,linux/arm64</code>. Multi-platform builds are pushed directly to registry. <pre><code>$ build --file docker/Dockerfile.build --skip-login --build-arg AUTH_TOKEN=abc\n</code></pre>"},{"location":"commands/build/#build-args","title":"Build-args","text":"<p>The following build-arg are automatically made available:</p> Arg Value <code>CI_COMMIT</code> The commit being built as exposed by CI <code>CI_BRANCH</code> The branch being built as exposed by CI <p>they can be used in a <code>Dockerfile</code> like:</p> <pre><code>FROM ubuntu\nARG CI_BRANCH\n\nRUN echo \"Building $CI_BRANCH\"\n</code></pre>"},{"location":"commands/build/#export-content-from-build","title":"Export content from build","text":"<p>Buildtools <code>build</code> command support exporting content from the actual docker build process, see Custom build outputs. By specifying a special stage in the <code>Dockerfile</code> and name it <code>export</code> you can use the <code>COPY</code> directive to copy files from the build context to the local machine. The copied files will be placed in a folder <code>exported</code></p>"},{"location":"commands/build/#example","title":"Example","text":"<p>Consider a <code>Dockerfile</code> like this:</p> <pre><code>FROM debian as build\nRUN echo \"text to be copied to localhost\" &gt;&gt; /testfile\n\n# -- export stage\nFROM scratch as export\n# Copies the file /testfile from `build` stage to localhost\nCOPY --from=build  /testfile .\n\n# -- resulting image stage\nFROM scratch\n# Do other stuff\n</code></pre> <p>Let's try it:</p> <pre><code>$ ls\nDockerfile\n\n$ cat Dockerfile\nFROM debian as build\nRUN echo \"text to be copied to localhost\" &gt;&gt; /testfile\n\n# -- export stage\nFROM scratch as export\n# Copies the file /testfile from `build` stage to localhost\nCOPY --from=build  /testfile .\n\n# -- resulting image stage\nFROM scratch\n# Do other stuff\n$ build\n... &lt;build output&gt;\n$ ls\nDockerfile  exported\n\n$ ls exported\ntestfile\n\n$ cat exported/testfile\ntext to be copied to localhost\n</code></pre>"},{"location":"commands/build/#multi-platform-builds","title":"Multi-platform builds","text":"<p>Build-tools supports building Docker images for multiple platforms (architectures) simultaneously using buildkit's native multi-platform support. This is useful for creating images that can run on different architectures like AMD64, ARM64, ARM/v7, etc.</p>"},{"location":"commands/build/#basic-usage","title":"Basic usage","text":"<p>To build for multiple platforms, provide a comma-separated list of platform identifiers:</p> <pre><code>$ build --platform linux/amd64,linux/arm64\n</code></pre> <p>Common platforms: - <code>linux/amd64</code> - 64-bit x86 (Intel/AMD) - <code>linux/arm64</code> - 64-bit ARM (Apple Silicon, ARM servers) - <code>linux/arm/v7</code> - 32-bit ARM (Raspberry Pi 3+, older ARM devices) - <code>linux/arm/v6</code> - 32-bit ARM (Raspberry Pi 1/2, older ARM devices)</p>"},{"location":"commands/build/#how-it-works","title":"How it works","text":"<p>Multi-platform builds: 1. Build the image for all specified platforms in parallel using buildkit 2. Create a manifest list that references all platform-specific images 3. Push directly to the configured registry (multi-platform manifests cannot be loaded to local Docker daemon) 4. Tag all platform images with the same tags (commit, branch, latest if applicable)</p> <p>Important notes: - Multi-platform builds require buildkit (Docker 19.03+) - Images are automatically pushed to the registry during the build process - You may need QEMU for cross-platform emulation if building on a single architecture - Multi-platform builds are typically slower than single-platform builds</p>"},{"location":"commands/build/#example_1","title":"Example","text":"<pre><code># Build for AMD64 and ARM64\n$ build --platform linux/amd64,linux/arm64\n\n# The built images will be pushed to the registry with manifest list support\n# Clients pulling the image will automatically get the correct architecture\n</code></pre>"},{"location":"commands/build/#requirements","title":"Requirements","text":"<p>Option 1: Use a standalone BuildKit instance (recommended)</p> <p>Set the <code>BUILDKIT_HOST</code> environment variable to connect directly to a buildkit instance:</p> <pre><code># Example: connect to buildkit running in a container\nexport BUILDKIT_HOST=docker-container://buildkitd\n\n# Example: connect to buildkit via TCP\nexport BUILDKIT_HOST=tcp://localhost:1234\n\n# Example: connect to buildkit via Unix socket\nexport BUILDKIT_HOST=unix:///run/buildkit/buildkitd.sock\n</code></pre> <p>You can run a standalone buildkit container:</p> <pre><code>docker run -d --name buildkitd --privileged moby/buildkit:latest\n</code></pre> <p>BUILDKIT_HOST behavior</p> <p>When <code>BUILDKIT_HOST</code> is set, all builds (single-platform and multi-platform) use the buildkit client directly. Images are pushed to the registry during the build, so the <code>push</code> command becomes a no-op.</p> <p>Option 2: Enable containerd snapshotter in Docker</p> <p>If not using <code>BUILDKIT_HOST</code>, multi-platform builds require Docker to be configured with the containerd snapshotter. This is because Docker's default storage driver doesn't support the image exporter needed for multi-platform manifest lists.</p> <p>Enable it by adding to <code>/etc/docker/daemon.json</code>:</p> <pre><code>{\n  \"features\": {\n    \"containerd-snapshotter\": true\n  }\n}\n</code></pre> <p>Then restart Docker:</p> <pre><code>sudo systemctl restart docker\n</code></pre> <p>QEMU for Cross-Platform Emulation:</p> <p>For cross-platform builds (e.g., building ARM on x86), you may need to set up QEMU:</p> <pre><code>docker run --privileged --rm tonistiigi/binfmt --install all\n</code></pre> <p>This is typically pre-configured in most CI/CD environments (GitHub Actions, GitLab CI, etc.).</p>"},{"location":"commands/build/#layer-caching-with-ecr","title":"Layer caching with ECR","text":"<p>When using buildkit (via <code>BUILDKIT_HOST</code>), you can configure AWS ECR as a remote layer cache backend. This significantly speeds up builds by caching intermediate layers in an ECR repository.</p>"},{"location":"commands/build/#configuration","title":"Configuration","text":"<p>Add the following to your <code>.buildtools.yaml</code>:</p> <pre><code>cache:\n  ecr:\n    url: 123456789.dkr.ecr.us-east-1.amazonaws.com/my-cache-repo\n    tag: buildcache  # optional, defaults to \"buildcache\"\n</code></pre> <p>Or use environment variables:</p> <pre><code>export BUILDTOOLS_CACHE_ECR_URL=123456789.dkr.ecr.us-east-1.amazonaws.com/my-cache-repo\nexport BUILDTOOLS_CACHE_ECR_TAG=buildcache  # optional\n</code></pre>"},{"location":"commands/build/#how-it-works_1","title":"How it works","text":"<p>When ECR cache is configured:</p> <ol> <li>Cache import: Before building, buildkit attempts to pull cached layers from the ECR repository</li> <li>Cache export: After building, buildkit pushes all cached layers to the ECR repository using <code>mode=max</code> (caches all stages)</li> <li>ECR-compatible format: Uses <code>image-manifest=true</code> and <code>oci-mediatypes=true</code> for ECR compatibility</li> </ol>"},{"location":"commands/build/#requirements_1","title":"Requirements","text":"<ul> <li><code>BUILDKIT_HOST</code> must be set (ECR cache only works with buildkit client)</li> <li>The ECR repository for cache must exist before running the build</li> <li>AWS credentials must have access to both the image registry and cache registry</li> </ul>"},{"location":"commands/build/#example_2","title":"Example","text":"<pre><code># Create the cache repository in ECR (one-time setup)\naws ecr create-repository --repository-name my-cache-repo\n\n# Configure buildkit and run the build\nexport BUILDKIT_HOST=docker-container://buildkitd\nexport BUILDTOOLS_CACHE_ECR_URL=123456789.dkr.ecr.us-east-1.amazonaws.com/my-cache-repo\n\nbuild --platform linux/amd64,linux/arm64\n</code></pre> <p>Separate cache repository</p> <p>It's recommended to use a dedicated ECR repository for cache storage, separate from your image repositories. This allows you to apply different lifecycle policies and keeps your cache isolated.</p>"},{"location":"commands/deploy/","title":"deploy","text":"<p>Deploys the built application to a Kubernetes cluster. Normal usage <code>deploy &lt;target&gt;</code>, but additional flags can be used to override:</p> Flag Description <code>--context</code>, <code>-c</code> Use a different context than the one found in configuration <code>--namespace</code>, <code>-n</code> Use a different namespace than the one found in configuration <code>--timeout</code>, <code>-t</code> Override the default deployment waiting time for completion (default 2 minutes). 0 means forever, all other values should contain a corresponding time unit (e.g. 1s, 2m, 3h) <code>--tag</code> Override the default tag to use (instead of the current commit tag or the value from CI) <code>--no-wait</code> Don't wait for deployment to become ready"},{"location":"commands/deploy/#default-usage-with-buildtoolsyaml-file","title":"Default usage, with <code>.buildtools.yaml</code> file","text":"<p>Only the <code>target</code> name has to be specified <pre><code>$ deploy local\n</code></pre></p>"},{"location":"commands/deploy/#overriding-namespace-from-config","title":"Overriding namespace from config:","text":"<pre><code>$ deploy --namespace test local\n</code></pre>"},{"location":"commands/deploy/#usage-without-buildtoolsyaml-file","title":"Usage without <code>.buildtools.yaml</code> file","text":"<p>In this case we need to at least specify the Kubernetes context to use for deployment: <pre><code>$ deploy --context docker-desktop\n</code></pre></p> <p>This will set the <code>namespace</code> to <code>default</code></p>"},{"location":"commands/deploy/#specifying-namespace","title":"Specifying namespace:","text":"<pre><code>$ deploy --context docker-desktop --namespace test\n</code></pre>"},{"location":"commands/kubecmd/","title":"kubecmd","text":"<p>Generates a kubectl command, using the configuration from .buildtools.yaml if found. Normal usage <code>kubecmd &lt;target&gt;</code>, but additional flags can be used to override:</p> Flag Description <code>--context</code>, <code>-c</code> Use a different context than the one found in configuration <code>--namespace</code>, <code>-n</code> Use a different namespace than the one found in configuration"},{"location":"commands/kubecmd/#default-usage-with-buildtoolsyaml-file","title":"Default usage, with <code>.buildtools.yaml</code> file","text":"<p>Only the <code>target</code> name has to be specified <pre><code>$ kubecmd local\nkubectl --context docker-desktop --namespace default\n</code></pre></p>"},{"location":"commands/kubecmd/#overriding-namespace-from-config","title":"Overriding namespace from config:","text":"<pre><code>$ kubecmd --namespace test local\nkubectl --context docker-desktop --namespace test\n</code></pre>"},{"location":"commands/promote/","title":"promote","text":"<p>Templates deployment descriptors and promotes them to a Git-repository of choice. Normal usage <code>promote &lt;target&gt;</code>, but additional flags can be used to override:</p> Flag Description <code>--tag</code> Override the default tag to use (instead of the current commit tag or the value from CI) <code>--url</code> override the URL to the Git repository where files will be generated <code>--path</code> override the path in the Git repository where files will be generated <code>--user</code> username for Git access, defaults to <code>git</code> <code>--key</code> private key for Git access, defaults to <code>~/.ssh/id_rsa</code> <code>--password</code> password for private key, defaults to <code>\"\"</code> <code>--out</code> , <code>-o</code> write output to specified file instead of committing and pushing to Git"},{"location":"commands/promote/#default-usage-with-buildtoolsyaml-file","title":"Default usage, with <code>.buildtools.yaml</code> file","text":"<p>Only the <code>target</code> name has to be specified <pre><code>$ promote local\n</code></pre></p>"},{"location":"commands/promote/#generate-file-locally","title":"Generate file locally:","text":"<pre><code>$ promote --out out.yaml local\n</code></pre>"},{"location":"commands/push/","title":"push","text":"<p>Performs a Docker push of the image created by <code>build</code>.</p> <p>By following the conventions no additional flags are needed, but the following flags are available:</p> Flag Description <code>--file</code>,<code>-f</code> <code>&lt;path to Dockerfile&gt;</code> Used to override the default <code>Dockerfile</code> location (which is <code>$PWD</code>) <pre><code>$ push --file docker/Dockerfile.build\n</code></pre>"},{"location":"config/config/","title":"<code>.buildtools.yaml</code>","text":"<p>Configuration and setup is done in <code>.buildtools.yaml</code> file(s). A typical configuration file consists of a <code>registry</code> config and a list of <code>targets</code> to use.</p> Key Description registry registry registry to push to targets targets to deploy to git git configuration block gitops git repos to push descriptors to <p>Note: Multiple files can be used for more advanced usage</p>"},{"location":"config/config/#example","title":"Example","text":"<p>The following file specifies a Dockerhub registry and 2 deployment targets: <code>local-test</code> and <code>staging</code> <pre><code>registry:\n  dockerhub:\n    namespace: buildtool\ntargets:\n  local-test:\n    context: docker-desktop\n  staging:\n    context: staging-aws-eu-west-1\n    namespace: my-test\n</code></pre></p>"},{"location":"config/config/#configuration-file-from-environment-variables","title":"Configuration file from environment variables","text":"<p>A <code>.buildtools.yaml</code> file can be created by defining an environment variable in the build pipeline named <code>BUILDTOOLS_CONTENT</code>. This can be useful when setting up CI/CD pipelines where the file system is not easily accessible.</p> <p>On MacOS the value can be created and copied to the clipboard using the following snippet:</p> <pre><code>$ cat - &lt;&lt;EOF | base64 -w0 | pbcopy\ntargets:\n  local-test:\n    context: docker-desktop\n\nEOF\n</code></pre> <p><code>BUILDTOOLS_CONTENT</code> can be either a base64 encoded string or plain text.</p> <p>Note: If <code>BUILDTOOLS_CONTENT</code> is set, no other configuration files will be used.</p> <p>See the following sections for information on how to configure the different parts of the configuration files.</p>"},{"location":"config/files/","title":"Configuration files","text":"<p>The <code>.buildtools.yaml</code> file(s) must be present in the project folder or upwards in the directory structure. This lets you create a common <code>.buildtools.yaml</code> file to be used for a set of projects. The <code>.buildtools.yaml</code> files will then be merged together, and settings from the file closest to the project being used first.</p>"},{"location":"config/files/#example","title":"Example:","text":"<pre><code>$ tree\n.\n\u251c\u2500\u2500 customer1\n\u2502 \u251c\u2500\u2500 project1\n\u2502 \u2514\u2500\u2500 project2\n\u2514\u2500\u2500 customer2\n    \u2514\u2500\u2500 project1\n</code></pre> <p>Here we can choose to put a <code>.buildtools.yaml</code> file in the different <code>customer</code> directories since they (most likely) have different deployment configuration.</p> <p>But both <code>project1</code> and <code>project2</code> for <code>cutomer1</code> use the same repository, so we can share that.</p> <pre><code>$ cat .buildtools.yaml\ntargets:\n  local:\n    context: docker-desktop\n\n$ cat customer1/.buildtools.yaml\nregistry:\n  dockerhub:\n    namespace: buildtool\ntargets:\n  prod:\n    context: production\n    kubeconfig: ~/.kube/config.d/production.yaml\n\n$ cat customer1/project1/.buildtools.yaml\ntargets:\n  staging:\n    context: test\n\n$ cat customer1/project2/.buildtools.yaml\ntargets:\n  staging:\n    context: staging\n    namespace: project2\n\n$ cat customer2/project1/.buildtools.yaml\ntargets:\n  staging:\n    context: local\n    namespace: customer2\n</code></pre> <p>TODO Describe the different \"final\" settings</p>"},{"location":"config/git/","title":"Git","text":"<p>The <code>git</code> key in <code>.buildtools.yaml</code> defines the git configuration used for the project. This will primarily be used for CI pipelines to push deployment descriptors images, i.e the <code>promote</code> command.</p> Key Description <code>name</code> The name to use as author for the commit message <code>email</code> The email to use as author for the commit message <code>key</code> Override the default ssh key (<code>~/.ssh/id_rsa</code>)"},{"location":"config/gitops/","title":"Gitops","text":"<p><code>gitops</code> is the equivalent to targets, but determines where the generated files from <code>promote</code> will end up.</p> <p>Each <code>&lt;name&gt;</code> must be unique and contains the git push url and the path inside the repository where the files will be stored.</p> <pre><code>gitops:\n  &lt;name&gt;:\n    url:\n    path:\n</code></pre> Parameter Description <code>url</code> The git URL (for example <code>git@github.com:buildtool/build-tools.git</code>) <code>path</code> Root path in the repository, files will be put under <code>$path/$name</code>, defaults to <code>/</code>"},{"location":"config/gitops/#examples","title":"Examples","text":"<pre><code>gitops:\n  local:\n    url: git@github.com:buildtool/build-tools.git\n    path: local\n  prod:\n    url: git@github.com:buildtool/build-tools.git\n    path: prod\n</code></pre>"},{"location":"config/k8s/","title":"Kubernetes","text":"<p>Descriptor files are placed in a <code>k8s</code> directory in the root of your project file. This directory contains all the yaml files used to describe the Kubernetes deployment tasks needed to run this service. Target specific files are handled by using a <code>-&lt;target&gt;</code> \"suffix\", i.e. <code>ingress-prod.yaml</code>.</p> <p>Files with a <code>.yaml</code> suffix will be applied to the Kubernetes cluster.</p> <p>If both a common file and a target-specific file with the same \"basename\", i.e. service.yaml and service-local.yaml, only the target-specific file will be applied for a <code>target</code> and the common file will be applied to all other targets.</p> <p>Files with a <code>.sh</code> suffix will be run on the machine executing the <code>deploy</code> command. This can be useful to setup secrets/configurations, mostly for local use. Note that only <code>.sh</code> files matching the <code>target</code> using the rules in the above paragraph will be executed, with the difference that no common files will be executed.</p> <p>All other files in <code>k8s</code> will be ignored by the <code>deploy</code> command.</p>"},{"location":"config/k8s/#available-variables","title":"Available variables","text":"<p>The following variables are possible to use for substitution in the descriptor files:</p> Parameter Description <code>IMAGE</code> The full image name (<code>registry/name:tag</code>) <code>COMMIT</code> The commit SHA (<code>3b701067e6a6943c773b9dc183fcc39cd31a2ff0</code>) <code>TIMESTAMP</code> The current time (<code>2022-02-22T09:16:01+01:00</code>)"},{"location":"config/k8s/#example","title":"Example","text":"<pre><code>$ cd projecct\n$ tree\n.\n\u2514\u2500\u2500 k8s\n    \u251c\u2500\u2500 deploy.yaml\n    \u251c\u2500\u2500 ingress-local.yaml\n    \u251c\u2500\u2500 ingress-prod.yaml\n    \u251c\u2500\u2500 service.yaml\n    \u251c\u2500\u2500 service-local.yaml\n    \u2514\u2500\u2500 setup-local.sh\n    \u2514\u2500\u2500 skipped.sh\n</code></pre> <p>Given the structure above:</p> <pre><code>deploy local\n</code></pre> <p>Will apply <code>deploy.yaml</code>, <code>ingress-local.yaml</code> and <code>service-local.yaml</code> and execute <code>setup-local.sh</code>.</p> <pre><code>deploy staging\n</code></pre> <p>Will apply <code>deploy.yaml</code> and <code>service.yaml</code>.</p> <pre><code>deploy prod\n</code></pre> <p>Will apply <code>deploy.yaml</code>, <code>ingress-prod.yaml</code> and <code>service.yaml</code>.</p>"},{"location":"config/registry/","title":"Registry","text":"<p>The <code>registry</code> key in <code>.buildtools.yaml</code> defines the docker registry used for the project. This will primarily be used for CI pipelines to push built docker images, i.e the <code>push</code> command.</p> <p>Locally it can be used to build images with correct tags, making it possible to deploy locally built images.</p> <p>Each supported registry has their own configuration keys, typically the setup looks like this:</p> <pre><code>registry:\n  &lt;registry name&gt;:\n    &lt;specific config&gt;\n</code></pre>"},{"location":"config/registry/#supported-registries","title":"Supported registries","text":"<p>The following registries are supported:</p> Config key Container registry <code>dockerhub</code> Docker hub <code>acr</code> Azure Container Registry <code>ecr</code> AWS Elastic Container Registry <code>github</code> Github package registry <code>gitlab</code> Gitlab container registry <code>quay</code> Quay docker registry <code>gcr</code> Google Container registry"},{"location":"config/registry/#dockerhub","title":"dockerhub","text":"Parameter Description Env variable <code>namespace</code> The namespace to publish to <code>DOCKERHUB_NAMESPACE</code> <code>username</code> User to authenticate <code>DOCKERHUB_USERNAME</code> <code>password</code> Password for <code>user</code> authentication <code>DOCKERHUB_PASSWORD</code>"},{"location":"config/registry/#acr","title":"acr","text":"<p>A valid Azure CLI session must be available (via <code>az login</code>), read more here.</p> Parameter Description Env variable <code>url</code> The ACR registry URL <code>ACR_URL</code> <code>tenantId</code> The id of the Azure tenant where the registry belongs to) <code>ACR_TENANT_ID</code>"},{"location":"config/registry/#ecr","title":"ecr","text":"<p>AWS Credentials must be supplied as <code>ENV</code> variables, read more here.</p> Parameter Description Env variable <code>url</code> The ECR registry URL <code>ECR_URL</code> <code>region</code> Specify a region (if it's possible to derive from the <code>url</code> parameter it can be omitted) <code>ECR_REGION</code>"},{"location":"config/registry/#github","title":"github","text":"<p>To authenticate <code>token</code> or a combination of <code>username</code> and <code>password</code> must be provided.</p> Parameter Description Env variable <code>repository</code> The repository part of the docker image name <code>GITHUB_REPOSITORY</code> <code>username</code> User to authenticate <code>GITHUB_USERNAME</code> <code>password</code> Password for <code>user</code> authentication <code>GITHUB_PASSWORD</code> <code>token</code> A personal access token to use for authentication <code>GITHUB_TOKEN</code>"},{"location":"config/registry/#gitlab","title":"gitlab","text":"Parameter Description Env variable <code>registry</code> The registry part of the docker image name <code>CI_REGISTRY</code> <code>repository</code> The repository part of the docker image name <code>CI_REGISTRY_IMAGE</code> <code>user</code> User to authenticate <code>CI_REGISTRY_USER</code> <code>token</code> A personal access token to use for authentication <code>CI_JOB_TOKEN</code>"},{"location":"config/registry/#quay","title":"quay","text":"Parameter Description Env variable <code>repository</code> The repository part of the docker image name <code>QUAY_REPOSITORY</code> <code>username</code> User to authenticate <code>QUAY_USERNAME</code> <code>password</code> Password for <code>user</code> authentication <code>QUAY_PASSWORD</code>"},{"location":"config/registry/#gcr","title":"gcr","text":"<p>GCP Credentials must be supplied as service account json key (Base64 encoded)</p> Parameter Description Env variable <code>url</code> The GCR registry URL <code>GCR_URL</code> <code>keyfileContent</code> ServiceAccount keyfile content <code>GCR_KEYFILE_CONTENT</code>"},{"location":"config/targets/","title":"Targets","text":"<p><code>targets</code> specifies the different 'deployment targets' to use for the project. The target match Kubernetes cluster configurations to deploy projects. Setting up Kubernetes contexts and namespaces is not handled by these tools.</p> <p>The only required configuration is <code>context</code> and <code>&lt;name&gt;</code> must be unique.</p> <pre><code>targets:\n  &lt;name&gt;:\n    context:\n    namespace:\n    kubeconfig:\n</code></pre> Parameter Default Description <code>context</code> Which context in the Kubernetes configuration to use <code>namespace</code> <code>default</code> Specific namespace to deploy to <code>kubeconfig</code> value of <code>KUBECONFIG</code> environment variable Full path to a specific kubeconfig file to use <p>The <code>KUBECONFIG_CONTENT</code> environment variable (probably most useful in CI/CD pipelines) can be used to provide the content of a \"kubeconfig\" file. If set, buildtools will create a temporary file with that content to use as the <code>kubeconfig</code> value. <code>KUBECONFIG_CONTENT</code> can be either a base64 encoded string or plain text.</p> <p>When deploying from inside a cluster, set <code>context: in-cluster</code> and make sure that the Pod has the appropriate permissions.</p> <p>Note: the <code>kubeconfig</code> parameter in config file overrides both the <code>KUBECONFIG</code> and <code>KUBECONFIG_CONTENT</code> environment variables if set.</p>"},{"location":"config/targets/#examples","title":"Examples","text":"<pre><code>targets:\n  local:\n    context: docker-desktop\n    namespace: default\n  local-test:\n    context: docker-desktop\n    namespace: test\n</code></pre>"}]}